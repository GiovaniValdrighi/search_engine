{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "from unicodedata import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_index(text, id_text):\n",
    "    # atualizamos o índice da lista invertida\n",
    "    text = text.lower()\n",
    "    text = re.sub('[^a-z0-9]+', ' ', text)\n",
    "    for w in text.split():\n",
    "        # limpeza das palavras: pode ser revisitado\n",
    "        w = w.strip(string.punctuation)\n",
    "        w = w.strip(\",.;:\\\"+=\")\n",
    "        w = normalize('NFKD', w).encode('ASCII', 'ignore').decode('ASCII')\n",
    "        \n",
    "        # atualizamos o index com as palavras\n",
    "        if w not in index.keys():\n",
    "            index[w] = []\n",
    "        index[w].append(id_text)\n",
    "\n",
    "def analise_texto(texto):\n",
    "    inicio = 0\n",
    "    # continuamos para cada tag \"<doc>\" encontrada\n",
    "    while texto.find('<doc id', inicio) != -1:\n",
    "        inicio = texto.find('<doc id', inicio)\n",
    "        \n",
    "        # separamos o \"id\" do artigo\n",
    "        inic_id = texto.find('id=\"', inicio)\n",
    "        fim_id = texto.find('\"', inic_id+4)\n",
    "        id_trecho = int(texto[inic_id+4:fim_id])\n",
    "        \n",
    "        # separamos o \"corpo\" do artigo\n",
    "        inicio = texto.find('\">', inicio)\n",
    "        fim = texto.find('</doc>', inicio)\n",
    "        trecho = texto[inicio+2:fim]\n",
    "        \n",
    "        update_index(trecho, id_trecho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Terminei a iteração 1\n"
     ]
    }
   ],
   "source": [
    "# Lemos os arquivos do diretório\n",
    "files = os.listdir()\n",
    "files.remove('inverted_index.ipynb')\n",
    "files.remove('.ipynb_checkpoints')\n",
    "files.remove('.git')\n",
    "# Para cada arquivo no diretório avaliamos\n",
    "# o texto e atualizamos o index de palavras\n",
    "index = {}\n",
    "k = 1\n",
    "for file in files:\n",
    "    f = open(file)\n",
    "    texto = f.read()\n",
    "    analise_texto(texto)\n",
    "    print('Terminei a iteração ' + str(k))\n",
    "    k += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# salvo index em um arquivo \".txt\"\n",
    "with open('index.txt', 'a+') as file:\n",
    "    for key in index.keys():\n",
    "        if key.isalpha():\n",
    "            s = str()\n",
    "            index[key] = list(np.unique(index[key]))\n",
    "            index[key].sort()\n",
    "            for k in index[key]:\n",
    "                s += ' ' + str(k)\n",
    "            file.write(str(key) + \" \" + str(len(index[key])) + \" \" + s  + \"\\n\")        \n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problemas do pré processamento:\n",
    "\n",
    "O método de tornar a lista única, é eficiente?\n",
    "\n",
    "Separar os arquivos salvos em vários arquivos de texto, não apenas um."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
